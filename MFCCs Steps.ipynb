{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T00:28:32.585143Z",
     "start_time": "2021-12-06T00:28:32.582142Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T00:28:32.980175Z",
     "start_time": "2021-12-06T00:28:32.587141Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "import librosa\n",
    "\n",
    "sample_rate, signal = scipy.io.wavfile.read('./audio/OSR_us_000_0010_8k.wav')  # File assumed to be in the same directory\n",
    "signal = signal[0:int(3.5 * sample_rate)]  # Keep the first 3.5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T00:28:32.996176Z",
     "start_time": "2021-12-06T00:28:32.984175Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_emphasis = 0.97\n",
    "frame_size = 0.025\n",
    "frame_stride = 0.01\n",
    "NFFT = 512\n",
    "nfilt = 40\n",
    "num_ceps = 12\n",
    "cep_lifter = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T00:28:33.106693Z",
     "start_time": "2021-12-06T00:28:32.999176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-Emphasis\n",
    "emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "\n",
    "\n",
    "# Framing\n",
    "frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
    "signal_length = len(emphasized_signal)\n",
    "frame_length = int(round(frame_length))\n",
    "frame_step = int(round(frame_step))\n",
    "num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "\n",
    "pad_signal_length = num_frames * frame_step + frame_length\n",
    "z = numpy.zeros((pad_signal_length - signal_length))\n",
    "pad_signal = numpy.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "frames_ret = pad_signal[indices.astype(numpy.int32, copy=False)]\n",
    "\n",
    "\n",
    "# Window\n",
    "frames = frames_ret * numpy.hamming(frame_length)\n",
    "# frames *= 0.54 - 0.46 * numpy.cos((2 * numpy.pi * n) / (frame_length - 1))  # Explicit Implementation **\n",
    "\n",
    "\n",
    "# Fourier-Transform and Power Spectrum\n",
    "mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
    "pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
    "\n",
    "\n",
    "# Filter Banks\n",
    "low_freq_mel = 0\n",
    "high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
    "mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
    "hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)\n",
    "\n",
    "fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / 2 + 1))))\n",
    "for m in range(1, nfilt + 1):\n",
    "    f_m_minus = int(bin[m - 1])   # left\n",
    "    f_m = int(bin[m])             # center\n",
    "    f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "    for k in range(f_m_minus, f_m):\n",
    "        fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "    for k in range(f_m, f_m_plus):\n",
    "        fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "filter_banks = numpy.dot(pow_frames, fbank.T)\n",
    "filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "filter_banks = 20 * numpy.log10(filter_banks)  # dB\n",
    "\n",
    "\n",
    "# Mel-frequency Cepstral Coefficients (MFCCs)\n",
    "mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13\n",
    "\n",
    "delta = librosa.feature.delta(mfcc)\n",
    "delta_delta = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "(nframes, ncoeff) = mfcc.shape\n",
    "n = numpy.arange(ncoeff)\n",
    "lift = 1 + (cep_lifter / 2) * numpy.sin(numpy.pi * n / cep_lifter)\n",
    "mfcc *= lift  #*\n",
    "\n",
    "\n",
    "# Mean Normalization\n",
    "filter_banks_norm = filter_banks - (numpy.mean(filter_banks, axis=0) + 1e-8)\n",
    "mfcc_norm = mfcc - (numpy.mean(mfcc, axis=0) + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Gráficos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T00:28:36.231146Z",
     "start_time": "2021-12-06T00:28:33.107694Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para a plotagem dos gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T00:28:36.263149Z",
     "start_time": "2021-12-06T00:28:36.232146Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotSound(audio, sr, title='Sinal no domínio do tempo'):\n",
    "    N = len(audio)\n",
    "    T = N/sr\n",
    "    t = np.linspace(0,T,N)\n",
    "    plt.figure(figsize=(12,2.5));\n",
    "    plt.plot(t,audio);\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xlabel('tempo (s)', fontsize=15); plt.ylabel('Amplitude', fontsize=15);\n",
    "    plt.grid(which='both')\n",
    "    plt.show()\n",
    "    ipd.display(ipd.Audio(audio, rate=sr, autoplay=False))\n",
    "\n",
    "def PreEnfase(signal,emphasized_signal, sr):\n",
    "    text = open('./texts/pre-emphasis.md', mode='r', encoding='utf-8').read()\n",
    "\n",
    "    ipd.display_markdown(text, raw=True)\n",
    "    plotSound(signal, sr, title='Sinal original no domínio do tempo')\n",
    "    plotSound(emphasized_signal, sr, title='Sinal enfatizado no domínio do tempo')\n",
    "    \n",
    "\n",
    "def plotWindow(frame_length):\n",
    "    plt.figure(figsize=(7,5));\n",
    "    plt.plot(numpy.hamming(frame_length));\n",
    "    plt.title('Janela Hamming', fontsize=18)\n",
    "    plt.xlabel('amostras', fontsize=15); plt.ylabel('Amplitude', fontsize=15);\n",
    "    plt.grid(which='both', linestyle='dotted')\n",
    "    plt.show()\n",
    "    \n",
    "def plotFrame(frame, title='Fragmento do sinal'):\n",
    "    plt.figure(figsize=(7,5));\n",
    "    plt.plot(frame);\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xlabel('amostras', fontsize=15); plt.ylabel('Amplitude', fontsize=15);\n",
    "    plt.grid(which='both', linestyle='dotted')\n",
    "    plt.show()\n",
    "\n",
    "def plotWindowed(frames, frame_length):\n",
    "    text1 = open('./texts/windowed1.md', mode='r', encoding='utf-8').read()\n",
    "    ipd.display_markdown(text1, raw=True)\n",
    "    plotWindow(frame_length)\n",
    "    nFrame=widgets.IntText(value=100, description='N° do frame:', disabled=False)\n",
    "    text2 = open('./texts/windowed2.md', mode='r', encoding='utf-8').read()\n",
    "    ipd.display_markdown(text2, raw=True)\n",
    "    plotFrame(frames[int(nFrame.value)], title=f'Frame n° {nFrame.value} janelado')\n",
    "\n",
    "def plotFrames(frames):\n",
    "    text = open('./texts/framing.md', mode='r', encoding='utf-8').read()\n",
    "    ipd.display_markdown(text, raw=True)\n",
    "    nFrame=widgets.IntText(value=100, description='N° do frame:', disabled=False)\n",
    "    plotFrame(frames[int(nFrame.value)], title=f'Frame n° {nFrame.value} janelado')\n",
    "    \n",
    "def plotSpectogram(frames, option):\n",
    "    if(option == 'Transformada de Fourier'):\n",
    "        text = open('./texts/fourier-Transform.md', mode='r', encoding='utf-8').read()\n",
    "        ipd.display_markdown(text, raw=True)\n",
    "    elif(option == 'Espectro de Potência'):\n",
    "        text = open('./texts/power-spectrum.md', mode='r', encoding='utf-8').read()\n",
    "        ipd.display_markdown(text, raw=True)\n",
    "    # Não é meu o código\n",
    "    plt.figure(figsize=(12, 2.5))\n",
    "    plt.imshow(np.flipud(frames.T), cmap=cm.jet, aspect=0.2, extent=[0,4,0,4])\n",
    "#     plt.specgram(frames)\n",
    "    plt.title('Spectrogram of the Signal')\n",
    "    plt.ylabel('Frequency (kHz)', fontsize=16)\n",
    "    plt.xlabel('Time (s)', fontsize=16)\n",
    "    plt.show()\n",
    "    # plt.savefig('filter_banks_raw2.png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "def plotFBank(fbank, sample_rate, low_freq):\n",
    "    plt.figure(figsize=(12,2.5))\n",
    "    plt.title('Banco de filtros MEL', fontsize=18)\n",
    "    plt.plot(np.linspace(low_freq, (sample_rate / 2), 257), fbank.T)\n",
    "    plt.xlabel('Frequências (escala MEL)',fontsize=15); plt.ylabel('Amplitude', fontsize=15);\n",
    "    plt.grid(which='both', linestyle='dotted')\n",
    "    plt.show()\n",
    "    # plt.savefig('mel_filters2.png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "def plotMFCC(num_ceps, mfcc):\n",
    "    text = open('./texts/mfcc.md', mode='r', encoding='utf-8').read()\n",
    "    ipd.display_markdown(text, raw=True)\n",
    "    plt.figure(figsize=(12, 2.5))\n",
    "    plt.imshow(np.flipud(mfcc.T), cmap=cm.jet, aspect=0.08, extent=[0,4,1,num_ceps])\n",
    "    plt.title('MFCCs', fontsize=18)\n",
    "    plt.xlabel('tempo (s)', fontsize=15); plt.ylabel('Coeficientes', fontsize=15);\n",
    "    plt.show()\n",
    "    # plt.savefig('mfcc_raw2.png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "def plotDelta(num_ceps, delta):\n",
    "    plt.figure(figsize=(12, 2.5))\n",
    "    plt.imshow(np.flipud(delta.T), cmap=cm.jet, aspect=0.08, extent=[0,4,1,num_ceps])\n",
    "    plt.title('Deltas', fontsize=18)\n",
    "    plt.xlabel('tempo (s)', fontsize=15); plt.ylabel('Coeficientes', fontsize=15);\n",
    "    plt.show()\n",
    "\n",
    "def plotDeltaDelta(num_ceps, delta_delta):\n",
    "    plt.figure(figsize=(12, 2.5))\n",
    "    plt.imshow(np.flipud(delta_delta.T), cmap=cm.jet, aspect=0.08, extent=[0,4,1,num_ceps])\n",
    "    plt.title('Deltas Deltas', fontsize=18)\n",
    "    plt.xlabel('tempo (s)', fontsize=15); plt.ylabel('Coeficientes', fontsize=15);\n",
    "    plt.show()\n",
    "\n",
    "def plotMFCC_librosa(mfcc):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    librosa.display.specshow(mfcc, x_axis='time', y_axis='frames')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plotMEL(fbank, sample_rate, low_freq_mel, filter_banks):\n",
    "    text = open('./texts/filter-Banks1.md', mode='r', encoding='utf-8').read()\n",
    "    ipd.display_markdown(text, raw=True)\n",
    "    plotFBank(fbank, sample_rate, low_freq_mel)\n",
    "    \n",
    "\n",
    "    text2 = open('./texts/filter-Banks2.md', mode='r', encoding='utf-8').read()\n",
    "    ipd.display_markdown(text2, raw=True)\n",
    "    plotSpectogram(filter_banks, None)\n",
    "   \n",
    "    \n",
    "def choosePlot(option=None):\n",
    "    if option==None: print(\"Escolha uma etapa para visualisar.\") \n",
    "    if option=='Pré-Enfase':             PreEnfase(signal,emphasized_signal, sample_rate)\n",
    "    if option=='Fragmentação':           plotFrames(frames_ret)\n",
    "    if option=='Janelamento':            plotWindowed(frames, frame_length)\n",
    "    if option=='Transformada de Fourier':plotSpectogram(mag_frames, 'Transformada de Fourier')\n",
    "    if option=='Espectro de Potência':   plotSpectogram(pow_frames, 'Espectro de Potência')\n",
    "    if option=='Banco de filtros MEL':   plotMEL(fbank, sample_rate, low_freq_mel, filter_banks)\n",
    "    if option=='MFCC':                   plotMFCC(num_ceps, mfcc)\n",
    "    if option=='Delta MFCC':             plotDelta(num_ceps, delta)\n",
    "    if option=='Delta Delta MFCC':       plotDeltaDelta(num_ceps, delta_delta)\n",
    "    if option=='MFCC normalizada':       plotMFCC(num_ceps, mfcc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T00:28:36.279151Z",
     "start_time": "2021-12-06T00:28:36.267150Z"
    }
   },
   "outputs": [],
   "source": [
    "# import ctypes  # An included library with Python install.\n",
    "# def Mbox(title, text, style):\n",
    "#     return ctypes.windll.user32.MessageBoxW(0, text, title, style)\n",
    "# Mbox('Banco de Filtros MEL', 'Filtros utilizados parar descatacar as variações nas baixas frequências.\\n\\nO ouvido humano tem uma percepção muito mais apurada das baixas frequências', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T00:28:36.391160Z",
     "start_time": "2021-12-06T00:28:36.283152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725095ea5f514ee3ae2abbf6def37270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Etapa:', options=('Pré-Enfase', 'Fragmentação', 'Janelamento', 'Tr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "Lista = ['Pré-Enfase','Fragmentação','Janelamento','Transformada de Fourier','Espectro de Potência','Banco de filtros MEL','MFCC','Delta MFCC','Delta Delta MFCC','MFCC normalizada']\n",
    "\n",
    "interact(choosePlot, option=widgets.Dropdown(options = Lista, \n",
    "                                             description='Etapa:', value=None,\n",
    "                                             disabled=False), continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências\n",
    "\n",
    "Haytham M. Fayek. (2016). Speech Processing for Machine Learning: Filter banks, Mel-Frequency Cepstral Coefficients (MFCCs) and What's In-Between."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d409983f81fa3db85743123dbc03164e0839ada0415b4c5f4cafe4a2ab9a966c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
